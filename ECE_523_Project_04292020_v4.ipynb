{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE_523_Project_04292020_v4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "npZAU5aUKE8x"
      },
      "source": [
        "! [ ! -z \"$COLAB_GPU\" ] && pip install torch scikit-learn==0.20.* skorch\n",
        "\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import Add, Input \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEnHhVE-QOjc"
      },
      "source": [
        "# This portion of the code is building a convolutional neural network\n",
        "# normalize the pixel values\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "#Define input shape\n",
        "input_shape = (32, 32, 3)\n",
        "filter_size1 = 512\n",
        "filter_size2 = 256\n",
        "filter_size3 = 128\n",
        "filter_size4 = 64\n",
        "filter_size5 = 10\n",
        "\n",
        "# Create three convolutional layers including dropout\n",
        "imgClassModel = Sequential()\n",
        "# Define 4 layers with filter size 64\n",
        "imgClassModel.add(Conv2D(filter_size4, kernel_size=(3,3), padding='same',activation='relu',use_bias=False,input_shape=input_shape))\n",
        "imgClassModel.add(BatchNormalization())\n",
        "#imgClassModel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "imgClassModel.add(Conv2D(filter_size4, kernel_size=(3,3), padding='same',activation='relu',use_bias=False))\n",
        "imgClassModel.add(BatchNormalization())\n",
        "imgClassModel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "\n",
        "# see the shape of each layer\n",
        "for layer in imgClassModel.layers:\n",
        "  print('First block')\n",
        "  print(layer.output_shape)\n",
        "\n",
        "# Define 4 layers with filter size 128\n",
        "imgClassModel.add(Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False))\n",
        "imgClassModel.add(BatchNormalization())\n",
        "#imgClassModel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "imgClassModel.add(Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False))\n",
        "imgClassModel.add(BatchNormalization())\n",
        "imgClassModel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "# see the shape of each layer\n",
        "for layer in imgClassModel.layers:\n",
        "  print('Second block')\n",
        "  print(layer.output_shape)\n",
        "\n",
        "# Define 2 layers with filter size 256\n",
        "imgClassModel.add(Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False))\n",
        "imgClassModel.add(BatchNormalization())\n",
        "#imgClassModel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "imgClassModel.add(Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False))\n",
        "imgClassModel.add(BatchNormalization())\n",
        "imgClassModel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "for layer in imgClassModel.layers:\n",
        "  print('Third block')\n",
        "  print(layer.output_shape)\n",
        "\n",
        "# Prepare the network to be \"fully connected\" by flattening the output\n",
        "imgClassModel.add(Flatten())\n",
        "\n",
        "# Define MLP the includes 1 hidden layer, and the output layer\n",
        "imgClassModel.add(Dense(filter_size4,activation='relu'))\n",
        "imgClassModel.add(Dropout(0.25))\n",
        "imgClassModel.add(Dense(filter_size5,activation='softmax'))\n",
        "\n",
        "# format class labels to be used in categorical cross entropy \n",
        "ytrain = to_categorical(y_train)\n",
        "ytest = to_categorical(y_test)\n",
        "\n",
        "# compile the CNN\n",
        "imgClassModel.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the CNN on your training data\n",
        "imgClassModel.fit(x_train,ytrain,epochs=200,batch_size=32)\n",
        "\n",
        "# predict on testing data\n",
        "imgClassModel.predict(x_test)\n",
        "imgClassModel.evaluate(x_test,ytest)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcmhgBdPI4C3"
      },
      "source": [
        "# This portion of the code is building a convolutional neural network w/ Resnet\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "#Define input shape\n",
        "input_shape = (32, 32, 3)\n",
        "filter_size1 = 512\n",
        "filter_size2 = 256\n",
        "filter_size3 = 128\n",
        "filter_size4 = 64\n",
        "filter_size5 = 10\n",
        "\n",
        "# Create three convolutional layers including dropout\n",
        "inputLayer = Input(shape=input_shape)\n",
        "#inputBlock = Conv2D(filter_size4, kernel_size=(7,7), padding='same',use_bias=False)(inputLayer)\n",
        "inputBlock = Conv2D(filter_size4, kernel_size=(1,1), padding='same',use_bias=False)(inputLayer)\n",
        "inputBlock = BatchNormalization()(inputBlock)\n",
        "\n",
        "# Define 2 layers with filter size 64\n",
        "hiddenBlock1 = Conv2D(filter_size4, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(inputBlock)\n",
        "hiddenBlock1 = BatchNormalization()(hiddenBlock1)\n",
        "hiddenBlock1 = Conv2D(filter_size4, kernel_size=(3,3), padding='same',use_bias=False)(hiddenBlock1)\n",
        "hiddenBlock1 = BatchNormalization()(hiddenBlock1)\n",
        "\n",
        "# Add output of layer from convolution block to Input to form residual \n",
        "resnetResult1 = Add()([inputBlock,hiddenBlock1])\n",
        "resnetResult1 = Activation('relu')(resnetResult1)\n",
        "resnetResult1 = BatchNormalization()(resnetResult1)\n",
        "#resnetResult1 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(resnetResult1)\n",
        "\n",
        "\n",
        "# Define 2 layers with filter size 128\n",
        "hiddenBlock2 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(resnetResult1)\n",
        "hiddenBlock2 = BatchNormalization()(hiddenBlock2)\n",
        "hiddenBlock2 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',use_bias=False)(hiddenBlock2)\n",
        "hiddenBlock2 = BatchNormalization()(hiddenBlock2)\n",
        "hiddenBlock2 = Dropout(0.25)(hiddenBlock2)\n",
        "\n",
        "# Add output of layer from convolution block to Input to form residual \n",
        "resnetResult_2 = Conv2D(filter_size3, kernel_size=(1,1), padding='same',use_bias=False)(resnetResult1) # make the same dimensions as filter size 128\n",
        "resnetResult_2 = Add()([resnetResult_2,hiddenBlock2])\n",
        "resnetResult2 = Activation('relu')(resnetResult_2)\n",
        "resnetResult2 = BatchNormalization()(resnetResult2)\n",
        "resnetResult2 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(resnetResult2) # (16,16,x)\n",
        "resnetResult2 = Dropout(0.25)(resnetResult2)\n",
        "\n",
        "# Define 2 layers with filter size 128\n",
        "hiddenBlock3 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(resnetResult2)\n",
        "hiddenBlock3 = BatchNormalization()(hiddenBlock3)\n",
        "hiddenBlock3 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock3)\n",
        "hiddenBlock3 = BatchNormalization()(hiddenBlock3)\n",
        "#hiddenBlock3 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(hiddenBlock3)\n",
        "hiddenBlock3 = Dropout(0.25)(hiddenBlock3)\n",
        "\n",
        "\n",
        "# Add output of layer from convolution block to Input to form residual \n",
        "resnetResult3 = Add()([resnetResult2,hiddenBlock3])\n",
        "resnetResult3 = Activation('relu')(resnetResult3)\n",
        "resnetResult3 = BatchNormalization()(resnetResult3)\n",
        "resnetResult3 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(resnetResult3) # (8,8,x)\n",
        "\n",
        "\n",
        "# Define 2 layers with filter size 256\n",
        "hiddenBlock4 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(resnetResult3)\n",
        "hiddenBlock4 = BatchNormalization()(hiddenBlock4)\n",
        "hiddenBlock4 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock4)\n",
        "hiddenBlock4 = BatchNormalization()(hiddenBlock4)\n",
        "hiddenBlock4 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(hiddenBlock4)\n",
        "hiddenBlock4 = Dropout(0.25)(hiddenBlock4)\n",
        "\n",
        "# Add output of layer from convolution block to Input to form residual \n",
        "#resnetResult_4 = Conv2D(filter_size2, kernel_size=(1,1), padding='same',use_bias=False)(resnetResult3) # make the same dimensions as filter size 256\n",
        "#resnetResult_4 = Add()([resnetResult_4,hiddenBlock4])\n",
        "#resnetResult4 = Activation('relu')(resnetResult_4)\n",
        "#resnetResult4 = BatchNormalization()(resnetResult4)\n",
        "#resnetResult4 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(resnetResult4)\n",
        "\n",
        "# Define 2 layers with filter size 256\n",
        "hiddenBlock5 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock4)\n",
        "hiddenBlock5 = BatchNormalization()(hiddenBlock5)\n",
        "hiddenBlock5 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',use_bias=False)(hiddenBlock5)\n",
        "hiddenBlock5 = BatchNormalization()(hiddenBlock5)\n",
        "hiddenBlock5 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(hiddenBlock5)\n",
        "hiddenBlock5 = Dropout(0.25)(hiddenBlock5)\n",
        "\n",
        "# Prepare the network to be \"fully connected\" by flattening the output\n",
        "hiddenBlock8 = Flatten()(hiddenBlock5)\n",
        "\n",
        "# Define MLP the includes 1 hidden layer, and the output layer\n",
        "hiddenBlock8 = Dense(filter_size4,activation='relu')(hiddenBlock8)\n",
        "hiddenBlock8 = Dropout(0.25)(hiddenBlock8)\n",
        "outputLayer = Dense(filter_size5,activation='softmax')(hiddenBlock8)\n",
        "\n",
        "# format class labels to be used in categorical cross entropy \n",
        "ytrain = to_categorical(y_train)\n",
        "ytest = to_categorical(y_test)\n",
        "\n",
        "resnetModel = Model(inputs = inputLayer, outputs = outputLayer)\n",
        "\n",
        "# compile the CNN\n",
        "resnetModel.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the CNN on your training data\n",
        "resnetModel.fit(x_train,ytrain,validation_data=(x_test, ytest),epochs=200,batch_size=32)\n",
        "\n",
        "ypredict = resnetModel.predict(x_test)\n",
        "\n",
        "#This gives the loss error and test accuracy\n",
        "test_e = resnetModel.evaluate(x_test,ytest)\n",
        "print(test_e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI_sSYamwRW_"
      },
      "source": [
        "# This portion of the code is the CNN with Resnet (but the skip connections are removed)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "#Define input shape\n",
        "input_shape = (32, 32, 3)\n",
        "filter_size1 = 512\n",
        "filter_size2 = 256\n",
        "filter_size3 = 128\n",
        "filter_size4 = 64\n",
        "filter_size5 = 10\n",
        "\n",
        "# Create three convolutional layers including dropout\n",
        "inputLayer = Input(shape=input_shape)\n",
        "#inputBlock = Conv2D(filter_size4, kernel_size=(7,7), padding='same',use_bias=False)(inputLayer)\n",
        "inputBlock = Conv2D(filter_size4, kernel_size=(1,1), padding='same',use_bias=False)(inputLayer)\n",
        "inputBlock = BatchNormalization()(inputBlock)\n",
        "\n",
        "# Define 2 layers with filter size 64\n",
        "hiddenBlock1 = Conv2D(filter_size4, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(inputBlock)\n",
        "hiddenBlock1 = BatchNormalization()(hiddenBlock1)\n",
        "hiddenBlock1 = Conv2D(filter_size4, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock1)\n",
        "hiddenBlock1 = BatchNormalization()(hiddenBlock1)\n",
        "\n",
        "# Define 2 layers with filter size 128\n",
        "hiddenBlock2 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock1)\n",
        "hiddenBlock2 = BatchNormalization()(hiddenBlock2)\n",
        "hiddenBlock2 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock2)\n",
        "hiddenBlock2 = BatchNormalization()(hiddenBlock2)\n",
        "hiddenBlock2 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(hiddenBlock2) # (16,16,x)\n",
        "hiddenBlock2 = Dropout(0.25)(hiddenBlock2)\n",
        "\n",
        "# Define 2 layers with filter size 128\n",
        "hiddenBlock3 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock2)\n",
        "hiddenBlock3 = BatchNormalization()(hiddenBlock3)\n",
        "hiddenBlock3 = Conv2D(filter_size3, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock3)\n",
        "hiddenBlock3 = BatchNormalization()(hiddenBlock3)\n",
        "hiddenBlock3 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(hiddenBlock3) # (8,8,x)\n",
        "hiddenBlock3 = Dropout(0.25)(hiddenBlock3)\n",
        "\n",
        "# Define 2 layers with filter size 256\n",
        "hiddenBlock4 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock3)\n",
        "hiddenBlock4 = BatchNormalization()(hiddenBlock4)\n",
        "hiddenBlock4 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock4)\n",
        "hiddenBlock4 = BatchNormalization()(hiddenBlock4)\n",
        "hiddenBlock4 = MaxPooling2D(pool_size=(2,2),strides=(2,2))(hiddenBlock4)\n",
        "hiddenBlock4 = Dropout(0.25)(hiddenBlock4)\n",
        "\n",
        "# Define 2 layers with filter size 256\n",
        "hiddenBlock5 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',activation='relu',use_bias=False)(hiddenBlock4)\n",
        "hiddenBlock5 = BatchNormalization()(hiddenBlock5)\n",
        "hiddenBlock5 = Conv2D(filter_size2, kernel_size=(3,3), padding='same',use_bias=False)(hiddenBlock5)\n",
        "hiddenBlock5 = BatchNormalization()(hiddenBlock5)\n",
        "hiddenBlock5 = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(hiddenBlock5)\n",
        "hiddenBlock5 = Dropout(0.25)(hiddenBlock5)\n",
        "\n",
        "# Prepare the network to be \"fully connected\" by flattening the output\n",
        "hiddenBlock8 = Flatten()(hiddenBlock5)\n",
        "\n",
        "# Define MLP the includes 1 hidden layer, and the output layer\n",
        "hiddenBlock8 = Dense(filter_size4,activation='relu')(hiddenBlock8)\n",
        "hiddenBlock8 = Dropout(0.25)(hiddenBlock8)\n",
        "outputLayer = Dense(filter_size5,activation='softmax')(hiddenBlock8)\n",
        "\n",
        "# format class labels to be used in categorical cross entropy \n",
        "ytrain = to_categorical(y_train)\n",
        "ytest = to_categorical(y_test)\n",
        "\n",
        "resnetModel = Model(inputs = inputLayer, outputs = outputLayer)\n",
        "\n",
        "# compile the CNN\n",
        "resnetModel.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the CNN on your training data\n",
        "resnetModel.fit(x_train,ytrain,validation_data=(x_test, ytest),epochs=200,batch_size=32)\n",
        "\n",
        "ypredict = resnetModel.predict(x_test)\n",
        "\n",
        "#This gives the loss error and test accuracy\n",
        "test_e = resnetModel.evaluate(x_test,ytest)\n",
        "print(test_e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9SjBGSXuKsh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}